{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001B[1mroot                \u001B[0m][\u001B[1;32mINFO\u001B[0m   ]  Configured logging from /home/jw17943/dimpact/eam-core-provenance/src/eam_core/logconf.yml (\u001B[1mlog_configuration.py\u001B[0m:30)\n",
      "[\u001B[1mroot                \u001B[0m][\u001B[1;32mINFO\u001B[0m   ]  Logging already configured. (\u001B[1mlog_configuration.py\u001B[0m:15)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from eam_core.yaml_runner import *\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_383173/465861469.py:14: UnsafeLoaderWarning: \n",
      "The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n",
      "Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n",
      "Alternatively include the following in your code:\n",
      "\n",
      "  import warnings\n",
      "  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n",
      "\n",
      "In most other cases you should consider using 'safe_load(stream)'\n",
      "  yaml_struct = yaml.load(stream)\n"
     ]
    }
   ],
   "source": [
    "args = {'yamlfile':'../../tests/models/valid.yml', 'comment':'jupyter','local':True,       'filetype':'pdf','docker':True }\n",
    "\n",
    "class argsview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "args = argsview(args) \n",
    "\n",
    "\n",
    "yamlfile = args.yamlfile\n",
    "yaml_struct = None\n",
    "with open(yamlfile, 'r') as stream:\n",
    "    try:\n",
    "        yaml_struct = yaml.load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        logger.error(f'Error while loading yaml file {yamlfile} {exc}')\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001B[1mroot                \u001B[0m][\u001B[1;32mINFO\u001B[0m   ]  Running with parameters <__main__.argsview object at 0x7f8148b96f70> (\u001B[1m3327315392.py\u001B[0m:10)\n",
      "[\u001B[1mroot                \u001B[0m][\u001B[1;32mINFO\u001B[0m   ]  Running with local parameter data only. (\u001B[1myaml_runner.py\u001B[0m:403)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Analysis'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_383173/3327315392.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m \u001B[0mscenarios\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0myaml_struct\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Analysis'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'scenarios'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0mscenarios\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'default'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dimpact/env/lib/python3.8/site-packages/ruamel/yaml/comments.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    924\u001B[0m         \u001B[0;31m# type: (Any) -> Any\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    925\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 926\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mordereddict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    927\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    928\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmerged\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmerge_attrib\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Analysis'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "args = {'yamlfile':'../../tests/models/valid.yml', 'comment':'jupyter','local':True,       'filetype':'pdf','docker':True }\n",
    "\n",
    "class argsview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "args = argsview(args)                                        \n",
    "\n",
    "\n",
    "logger.info(f\"Running with parameters {args}\")\n",
    "model_run_base_directory, simulation_run_description, yaml_struct = load_configuration(args)\n",
    "\n",
    "\n",
    "scenarios = yaml_struct['Analysis'].get('scenarios', [])\n",
    "scenarios.append('default')\n",
    "\n",
    "runs = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "\n",
    "    print (f'running scenario {scenario}')\n",
    "    model_output_directory = model_run_base_directory + f\"/{scenario}\"\n",
    "    if not os.path.exists(model_output_directory):\n",
    "        os.makedirs(model_output_directory)\n",
    "\n",
    "    create_model_func, sim_control, yaml_struct = prepare_simulation(model_output_directory,\n",
    "                                                                 simulation_run_description, yaml_struct,\n",
    "                                                                 scenario)\n",
    "\n",
    "    runner = SimulationRunner()\n",
    "    model, footprint_result_dict = runner.run(create_model_func=create_model_func,\n",
    "                                              sim_control=sim_control,\n",
    "                                            debug=True,\n",
    "                                              target_units=YamlLoader.get_target_units(yaml_struct),\n",
    "                                             result_variables=yaml_struct['Analysis'].get('result_variables', []))\n",
    "    \n",
    "    runs.append((scenario, model, footprint_result_dict, sim_control, yaml_struct));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_vars = model.collect_input_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(i_vars['Playout']['mean_power_per_linear_channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = sim_control.output_directory\n",
    "base_dir = '.'\n",
    "metadata = load_metadata(output_directory, base_dir=base_dir)\n",
    "\n",
    "xlsx_file_name = f'{base_dir}/{output_directory}/results_{scenario}_{time.strftime(\"%m%d-%H%M\")}.xlsx'\n",
    "writer = pd.ExcelWriter(xlsx_file_name)\n",
    "sheet_descriptions = {}\n",
    "pd.DataFrame.from_dict(sheet_descriptions, orient='index').to_excel(writer, 'toc')\n",
    "# df of x samples, monthly frequency between start and end date\n",
    "load_data = load_as_df_qantity\n",
    "start_date = yaml_struct['Metadata']['start_date']\n",
    "end_date = yaml_struct['Metadata']['end_date']\n",
    "\n",
    "common_args = {'start_date': start_date,\n",
    "                       'end_date': end_date,\n",
    "                       'base_dir': base_dir,\n",
    "                       'metadata': metadata,\n",
    "                       'output_scenario_directory': output_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'energy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = str(q_data.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_data = load_data(f'{output_directory}/result_data_{variable}.hdf5')\n",
    "data = q_data.m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = plot_def['name']\n",
    "variable = plot_def['variable']\n",
    "logger.info(plot_def['name'])\n",
    "\n",
    "# sum up monthly values to aggregate - duration depends on distance between start and end date\n",
    "#    load_data_aggegrate = lambda : load_data().sum(level='samples')\n",
    "\n",
    "q_data = load_data(f'{output_directory}/result_data_{variable}.hdf5')\n",
    "data = q_data.m\n",
    "unit = str(data.units)\n",
    "xlabel = f'{unit}/a'\n",
    "common_args['xlabel']= xlabel        \n",
    "\n",
    "if 'groups' in plot_def:\n",
    "    data = group_data(data, metadata, plot_def)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_ylim([0,20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variable = 'energy'\n",
    "q_data = load_data(f'{output_directory}/result_data_{variable}.hdf5')\n",
    "data = q_data.m\n",
    "# get number of processes\n",
    "len(data.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "rows = math.ceil(len(data.columns) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_struct['Metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.abs().groupby(level=['time']).quantile(.75).values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.abs().groupby(level=['time']).quantile(.75).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.abs().groupby(level=['time']).quantile(.75).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.ix[:, data.abs().groupby(level=['time']).quantile(.75).max().sort_values(ascending=False).index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint max of 75th percentile \n",
    "# yhigh = data.abs().groupby(level=['time']).quantile(.75).values.max() * 1.1\n",
    "\n",
    "# joint min of 25th percentile \n",
    "# ylow = data.abs().groupby(level=['time']).quantile(.75).values.max() * 1.1\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "maxima = data[data.columns[0]].abs().groupby(level=['time']).quantile(.75).mean()\n",
    "minima = data[data.columns[-1]].abs().groupby(level=['time']).quantile(.75).mean()\n",
    "\n",
    "norm = matplotlib.colors.LogNorm(vmin=minima, vmax=maxima, clip=True)\n",
    "mapper = cm.ScalarMappable(norm=norm, cmap=cm.viridis_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "# sort\n",
    "data = data.ix[:, data.abs().groupby(level=['time']).quantile(.75).max().sort_values(ascending=False).index]\n",
    "\n",
    "n = len(data.columns)\n",
    "# fig = plt.figure(figsize=(12,n*0.75))\n",
    "rows = math.ceil(n/ 3)\n",
    "f, axarr = plt.subplots(rows,3,sharex='col', sharey='row')\n",
    "f.set_size_inches(10,n*0.5)\n",
    "\n",
    "# joint max of 75th percentile \n",
    "# yhigh = data.abs().groupby(level=['time']).quantile(.75).values.max() * 1.1\n",
    "\n",
    "# joint min of 25th percentile \n",
    "# ylow = data.abs().groupby(level=['time']).quantile(.75).values.max() * 1.1\n",
    "\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axarr.flat):    \n",
    "    \n",
    "    ax.set_title(data.columns[i])\n",
    "    process_name = data.columns[i]\n",
    "#     print(f'{i}: {process_name}')\n",
    "    \n",
    "    process_data = data[process_name]\n",
    "    mean_ = process_data.abs().mean(level='time')\n",
    "    \n",
    "    grouped_ = process_data.abs().groupby(level=['time'])\n",
    "    \n",
    "    low = grouped_.quantile(.25)  \n",
    "    high = grouped_.quantile(.75)\n",
    "    \n",
    "    mean_.plot(ax=ax,\n",
    "                                   kind='area',\n",
    "                                   legend=False,\n",
    "                                   linewidth=0.5, \n",
    "                                   color=mapper.to_rgba(high.mean())\n",
    "              )\n",
    "    \n",
    "    low.plot(ax=ax, color='k',alpha=0.2, linestyle=':')\n",
    "    high.plot(ax=ax, color='k',alpha=0.2, linestyle=':') \n",
    "    ax.fill_between(mean_.index.get_level_values(0), \n",
    "                     low, \n",
    "                     high, \n",
    "                     facecolor='k', \n",
    "#                      hatch=\"+\", \n",
    "                     edgecolor=\"k\", linewidth=0.1,\n",
    "                     alpha=0.1, interpolate=True, linestyle='-')\n",
    "#     ylim= process_data.abs().groupby(level=['time']).quantile(.75).values.max()\n",
    "#     print(f'{ylim}')\n",
    "    ax.set_xlabel('')\n",
    "f.text(0.5, -0.0, 'time', ha='center')\n",
    "f.text(-0.0, 0.5, unit, va='center', rotation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "    # data.abs().sum(axis=1).groupby(level=['time']).quantile(.25).plot(ax=ax, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.text(0.5, -0.0, 'time', ha='center')\n",
    "f.text(-0.0, 0.5, 'MWh', va='center', rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(axarr.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Simple data to display in various forms\n",
    "x = np.linspace(0, 2 * np.pi, 400)\n",
    "y = np.sin(x ** 2)\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fig = plt.figure(figsize=(12,n*0.75))\n",
    "rows = math.ceil(n/ 3)\n",
    "f, axarr = plt.subplots(rows, 3,sharex='col', sharey='row')\n",
    "\n",
    "for i, ax in enumerate(axarr.flat):    \n",
    "    for ax in axarr.flat:\n",
    "        ax.set_title('test')\n",
    "        ax.plot(x, y)\n",
    "#         ax.set(xlabel='x-label', ylabel='y-label')\n",
    "plt.tight_layout()\n",
    "\n",
    "#     axarr[0, 0].plot(x, y)\n",
    "# # f, axarr = plt.subplots(2, 2)\n",
    "# axarr[0, 0].plot(x, y)\n",
    "# axarr[0, 0].set_title('Axis [0,0]')\n",
    "# axarr[0, 1].scatter(x, y)\n",
    "# axarr[0, 1].set_title('Axis [0,1]')\n",
    "# axarr[1, 0].plot(x, y ** 2)\n",
    "# axarr[1, 0].set_title('Axis [1,0]')\n",
    "# axarr[1, 1].scatter(x, y ** 2)\n",
    "# axarr[1, 1].set_title('Axis [1,1]')\n",
    "# for ax in axarr.flat:\n",
    "#     ax.set(xlabel='x-label', ylabel='y-label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.set_size_inches(12a.5, 20.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.abs().mean(level='time').plot(ax=ax,\n",
    "                               kind='area',\n",
    "                               # legend=False,\n",
    "                               linewidth=0.5, colormap='Paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = data.abs().sum(axis=1).groupby(level=['time']).quantile(.25)\n",
    "low.plot(ax=ax, color='k',alpha=0.2, linestyle=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = data.abs().sum(axis=1).groupby(level=['time']).quantile(.75)\n",
    "high.plot(ax=ax, color='k',alpha=0.2, linestyle=':')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = high.max()\n",
    "ax.set_ylim([0,ylim*1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(data.mean(level='time').index.get_level_values(0), \n",
    "                 low, \n",
    "                 high, \n",
    "                 facecolor='k', \n",
    "                 hatch=\"+\", \n",
    "                 edgecolor=\"k\", linewidth=0.1,\n",
    "                 alpha=0.1, interpolate=True, linestyle='-')\n",
    "# data.abs().sum(axis=1).groupby(level=['time']).quantile(.25).plot(ax=ax, color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.legend(loc='center left', bbox_to_anchor=(.8, 0.5),\n",
    "          ncol=1, fancybox=True, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean(level='time').index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(f'{output_directory}/graph_data_{name}.pdpkl')\n",
    "d = plot_kind(data, figsize=(15, 12), file_name=f'{scenario}_{name}.pdf', title='Annual Total',\n",
    "                          kind=plot_def.get('kind', 'box'), **common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(f'{output_directory}/result_data_{variable}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Google Origin DC'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.index = data.index.droplevel(1)\n",
    "data.plot.area()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "rcParams_bkp = copy.deepcopy(plt.rcParams)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['axes.linewidth'] = .2\n",
    "plt.rcParams['axes.spines.top'] = True\n",
    "plt.rcParams['axes.spines.right'] = True\n",
    "plt.rcParams['axes.spines.bottom'] = True\n",
    "plt.rcParams['axes.spines.left'] = True\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams['grid.linestyle'] = ':'\n",
    "plt.rcParams['lines.linewidth'] = .1\n",
    "plt.rcParams['hatch.linewidth'] = 0.3\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "title = f'{title} ({kwargs[\"start_date\"]} - {kwargs[\"end_date\"]})'\n",
    "\n",
    "ax.set_ylabel(ylabel)\n",
    "ax.set_xlabel(xlabel)\n",
    "df.reindex_axis(df.mean().sort_values().index, axis=1)\n",
    "df.T.plot(ax=ax, kind='barh', legend=False, color='w', edgecolor='k', align='center', width=0.5,\n",
    "          linewidth=0.5, title=title)\n",
    "bars = ax.patches\n",
    "patterns = ['///', '--', '...', '\\///', 'xxx', '\\\\\\\\']\n",
    "hatches = [p for p in patterns for i in range(len(df))]\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "from textwrap import wrap\n",
    "ax.set_yticklabels(['\\n'.join(wrap(l.get_text(), 10)) for l in ax.get_yticklabels()])\n",
    "\n",
    "if file_name:\n",
    "    if not os.path.exists(f'{base_dir}/{output_scenario_directory}'):\n",
    "        os.makedirs(f'{base_dir}/{output_scenario_directory}')\n",
    "    file_name_ = f'{base_dir}/{output_scenario_directory}/{file_name}'\n",
    "    logger.info(f'storing plot at {file_name_}')\n",
    "    fig.savefig(file_name_)\n",
    "# restore\n",
    "plt.rcParams.update(rcParams_bkp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngmodel.common_graphical_analysis import plot_box, load_metadata\n",
    "from ngmodel.util import load_as_df_qantity\n",
    "from scenarios.graphical_analysis import sum_interval, group_by\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario=model.name\n",
    "output_directory = sim_control.output_directory\n",
    "base_dir='.'\n",
    "\n",
    "if 'start_date' in yaml_struct['Metadata']:\n",
    "    start_date = yaml_struct['Metadata']['start_date']\n",
    "    end_date = yaml_struct['Metadata']['end_date']\n",
    "    \n",
    "metadata = load_metadata(output_directory, base_dir=base_dir)\n",
    "\n",
    "load_data = partial(load_as_df_qantity, f'{output_directory}/result_data.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "   plots:\n",
    "    - name: device_groups\n",
    "      groups:\n",
    "        - name: Wired Access Network\n",
    "          included_types:\n",
    "          - Wired Access Network\n",
    "        - name: User Devices\n",
    "          included_types:\n",
    "          - Viewing Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_defs = yaml_struct['Analysis']['plots']\n",
    "\n",
    "for plot_def in plot_defs:\n",
    "    name = plot_def['name']\n",
    "    logger.info(plot_def['name'])\n",
    "    \n",
    "    data = load_data()\n",
    "    unit = str(data.units)\n",
    "\n",
    "    # sum up monthly values to aggregate - duration depends on distance between start and end date\n",
    "    #    load_data_aggegrate = lambda : load_data().sum(level='samples')\n",
    "    xlabel = f'{unit}/a'\n",
    "    common_args = {'start_date': start_date,\n",
    "                   'end_date': end_date,\n",
    "                   'base_dir': base_dir,\n",
    "                   'xlabel': xlabel,\n",
    "                   'metadata': metadata,\n",
    "                   'output_scenario_directory': output_directory}\n",
    "    data = sum_interval(data, start_date, end_date)\n",
    "    \n",
    "    if 'groups' in plot_def:\n",
    "        for group in plot_def['groups']:\n",
    "            group_name  = group['name']\n",
    "            \n",
    "            kwargs = {}\n",
    "            if 'included_types' in group:\n",
    "                included_types = group['included_types']\n",
    "                kwargs.update({'included_types':included_types})\n",
    "            \n",
    "            data = group_by(data, metadata=metadata, group_name=group_name, **kwargs)\n",
    "    \n",
    "    d = plot_box(data, figsize=(15, 12), file_name=f'{scenario}_{name}.pdf', title='annual total',\n",
    "             **common_args)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = group_user_devices(data, metadata=metadata)\n",
    "df = sum_interval(data, start_date, end_date)\n",
    "d = plot_box(df, figsize=(15, 12), file_name=f'{scenario}_plot_all_processes_annual.pdf', title='annual total',\n",
    "             **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot with Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_defs = yaml_struct['Analysis']['plots']\n",
    "plot_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=[[1,2,3]], columns=['a','b','c'], index=[1,2,3])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'a':{'device_type': 'Wired Access Network'},\n",
    "            'b':{'platform_name': 'DSL'},\n",
    "            'c':{'device_type': 'Viewing Device'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(df, pattern_list=None, group_name=None, metadata=None, included_types=None):    \n",
    "    ud_cols = []\n",
    "    for col in df.columns:\n",
    "        if not col in metadata:\n",
    "            # a column might be the result of a previous call to group_by. We do not want to include them in future operations.\n",
    "            # thus exclude them by checking that the name is present in the simulation metadata\n",
    "            continue\n",
    "        md = metadata[col]\n",
    "\n",
    "        # check the device type is correct\n",
    "        if not included_types or 'device_type' in md and md['device_type'] in included_types:\n",
    "            # check the name pattern matches\n",
    "            if not pattern_list or any(ud_name.lower() in col.lower() for ud_name in pattern_list):\n",
    "                ud_cols.append(col)\n",
    "\n",
    "    df[group_name] = df[ud_cols].sum(axis=1)\n",
    "    ud_df = df.drop(ud_cols, axis=1)\n",
    "    return ud_df\n",
    "df = group_by(data, metadata=metadata, group_name='TVs', included_types=['Viewing Device'], pattern_list=['c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = model.collect_input_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfs = {}\n",
    "for proc_name, vars in sorted(all_vars.items()):\n",
    "    p_df = None\n",
    "    for var_name, var in sorted(vars.items()):\n",
    "        if 'energy' in var_name:\n",
    "            continue\n",
    "#         print(proc_name, var_name, var)\n",
    "        if p_df is None:\n",
    "            p_df = pd.DataFrame(data=var.m)            \n",
    "            p_df.columns = [var_name]\n",
    "        else:\n",
    "            p_df[var_name] = var.m\n",
    "    \n",
    "    if not isinstance(p_df.index, pd.MultiIndex):\n",
    "        p_df.index = sim_control._df_multi_index\n",
    "    normalized_df=(p_df-p_df.min())/(p_df.max()-p_df.min())\n",
    "    \n",
    "    ndfs[proc_name] = normalized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ndfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_name = '4_5G Modem Router'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfs[process_name].mean(level='time').plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfs[process_name].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data = data[process_name]\n",
    "mean_ = process_data.abs().mean(level='time')\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "grouped_ = process_data.abs().groupby(level=['time'])\n",
    "\n",
    "low = grouped_.quantile(.25)  \n",
    "high = grouped_.quantile(.75)\n",
    "\n",
    "mean_.plot(ax=ax, kind='area',\n",
    "                               legend=False,\n",
    "                               linewidth=0.5, \n",
    "                               color='k', alpha=.3\n",
    "           \n",
    "          )\n",
    "\n",
    "ndfs[process_name].mean(level='time').plot.line(ax=ax, secondary_y=True, linewidth=0.3,)\n",
    "\n",
    "low.plot(ax=ax, color='k',alpha=0.2, linestyle=':')\n",
    "high.plot(ax=ax, color='k',alpha=0.2, linestyle=':') \n",
    "ax.fill_between(mean_.index.get_level_values(0), \n",
    "                 low, \n",
    "                 high, \n",
    "                 facecolor='k', \n",
    "#                      hatch=\"+\", \n",
    "                 edgecolor=\"k\", linewidth=0.1,\n",
    "                 alpha=0.1, interpolate=True, linestyle='-')\n",
    "\n",
    "\n",
    "ylim= process_data.abs().groupby(level=['time']).quantile(.75).values.max()\n",
    "#     print(f'{ylim}')\n",
    "# ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "args = {'yamlfile':'models/scenarios.yml', 'comment':'jupyter','local':True,       'filetype':'pdf','docker':True }\n",
    "\n",
    "class argsview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "args = argsview(args)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_base_directory, simulation_run_description, yaml_struct = load_configuration(args)\n",
    "\n",
    "scenarios = yaml_struct['Analysis'].get('scenarios', [])\n",
    "scenarios.append('default')\n",
    "\n",
    "model_name = None\n",
    "\n",
    "runners = {}\n",
    "\n",
    "for scenario in scenarios:\n",
    "    model_output_directory = model_run_base_directory + f\"/{scenario}\"\n",
    "    if not os.path.exists(model_output_directory):\n",
    "        os.makedirs(model_output_directory)\n",
    "\n",
    "    create_model_func, sim_control, yaml_struct = prepare_simulation(model_output_directory,\n",
    "                                                                     simulation_run_description, yaml_struct,\n",
    "                                                                     scenario)\n",
    "\n",
    "    runner = SimulationRunner()\n",
    "    runner.run(create_model_func=create_model_func,\n",
    "               sim_control=sim_control, debug=True,\n",
    "               target_units=YamlLoader.get_target_units(yaml_struct),\n",
    "               result_variables=yaml_struct['Analysis'].get('result_variables', []))\n",
    "\n",
    "    # analysis(runner.model, runner.sim_control, yaml_struct)\n",
    "    model_name = runner.model.name\n",
    "    runners[scenario] = runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario_name, run_data in runners.items():\n",
    "    print(scenario_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = runners['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'AO_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "output_directory = run_data.sim_control.output_directory\n",
    "q_data_a = load_data(f'{output_directory}/result_data_{variable}.hdf5')\n",
    "unit = str(q_data_a.units)\n",
    "\n",
    "data = q_data_a.m\n",
    "base_dir = '.'\n",
    "metadata = load_metadata(output_directory, base_dir=base_dir)\n",
    "\n",
    "# if 'groups' in plot_def:\n",
    "#     data = group_data(data, metadata, plot_def)\n",
    "\n",
    "mean_ = data.abs().mean(level='time').sum(axis=1)\n",
    "\n",
    "mean_.plot(ax=ax, kind='area',\n",
    "#            legend=False,\n",
    "           linewidth=0.5,\n",
    "           color='k', alpha=.3\n",
    "           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data a,\n",
    "# load data b\n",
    "load_data = load_as_df_qantity\n",
    "variable = 'energy'\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for scenario_name, run_data in runners.items():\n",
    "    output_directory = run_data.sim_control.output_directory\n",
    "    q_data_a = load_data(f'{output_directory}/result_data_{variable}.hdf5')\n",
    "    unit = str(q_data_a.units)\n",
    "\n",
    "    data = q_data_a.m\n",
    "    base_dir = '.'\n",
    "    metadata = load_metadata(output_directory, base_dir=base_dir)\n",
    "\n",
    "    # if 'groups' in plot_def:\n",
    "    #     data = group_data(data, metadata, plot_def)\n",
    "\n",
    "    mean_ = data.abs().mean(level='time').sum(axis=1)\n",
    "\n",
    "    mean_.plot(ax=ax, kind='line',\n",
    "#                legend=False,\n",
    "               linewidth=1,\n",
    "               alpha=.3,\n",
    "               label=scenario_name\n",
    "               )\n",
    "    \n",
    "ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "file_name = 'scenarios.pdf'\n",
    "if file_name:\n",
    "    if not os.path.exists(f'{base_dir}/{model_run_base_directory}'):\n",
    "        os.makedirs(f'{base_dir}/{model_run_base_directory}')\n",
    "    file_name_ = f'{base_dir}/{model_run_base_directory}/{file_name}'\n",
    "    logger.info(f'storing plot at {file_name_}')\n",
    "    fig.savefig(file_name_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = run.model.collect_input_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in model.process_graph.nodes():\n",
    "    print(n.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(all_vars.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vars = {}\n",
    "\n",
    "for _, p_vars in all_vars.items():\n",
    "    _vars.update(p_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_df = pd.DataFrame(data=_vars['total_iplayer_tablet_device_bits_per_day'].m)\n",
    "p_df.columns = ['total_iplayer_tablet_device_bits_per_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ = p_df.mean(level='time')\n",
    "mean_.plot(kind='line',\n",
    "                   legend=False,\n",
    "                   linewidth=1,\n",
    "                   color='k', alpha=.3,\n",
    "                   marker=\"x\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vars.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vars['adsl_access_network_energy_per_hh_per_reference_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(_vars.keys())[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "n = len(_vars)\n",
    "# n = 10\n",
    "rows = math.ceil(n / 3)\n",
    "f, axarr = plt.subplots(rows, 3, sharex='col', sharey=False)\n",
    "f.set_size_inches(10, n * 0.5)\n",
    "\n",
    "var_names = sorted(_vars.keys())\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    var_name = var_names[i]\n",
    "    val = _vars[var_name]\n",
    "# for var_name, val in sorted(_vars.items()):\n",
    "#     fig = plt.figure(figsize=(10, 5))\n",
    "#     ax = fig.add_subplot(111)\n",
    "\n",
    "    data = _vars[var_name].to_reduced_units()\n",
    "\n",
    "    p_df = pd.DataFrame(data=data.m)\n",
    "    p_df.columns = [var_name]\n",
    "    if not isinstance(p_df.index, pd.MultiIndex):\n",
    "        p_df.index = run.sim_control._df_multi_index\n",
    "        \n",
    "    mean_ = p_df.mean(level='time')\n",
    "    mean_.plot(ax=ax, kind='line',\n",
    "                   legend=False,\n",
    "                   linewidth=1,\n",
    "                   color='k', alpha=.3,\n",
    "#                    marker=\"x\"\n",
    "                   )\n",
    "    fig.suptitle(var_name, fontsize=16)\n",
    "\n",
    "    ax.set_ylabel(data.units)\n",
    "#     fig.title(var_name)\n",
    "    ax.set_title(var_name [:15])\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=.3)\n",
    "    fig.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}